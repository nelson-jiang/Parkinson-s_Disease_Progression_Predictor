{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "833ac03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "%matplotlib inline\n",
    "RAND_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f9be7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading csv\n",
    "CSV_NAME = \"parkinsons_disease_progression_500.csv\"\n",
    "# Skipping first row with column headers:\n",
    "# Patient_ID Age GenderS Years_Since_Diagnosis UPDRS_Score Tremor_Severity Motor_Function\tSpeech_Difficulty Balance_Problems Medications Exercise_Level Disease_Progression\n",
    "\n",
    "#raw_data = np.loadtxt(CSV_NAME, dtype=str, delimiter=\",\", skiprows=1)\n",
    "raw_data_df = pd.read_csv(CSV_NAME)\n",
    "raw_data = raw_data_df.to_numpy(dtype=str)\n",
    "feature_df = raw_data_df.drop(columns=['Disease_Progression'])\n",
    "target_df = raw_data_df['Disease_Progression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "06623238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into target and features\n",
    "X = raw_data[: , 1:11]  # Excluding first column with Patient ID\n",
    "y = raw_data[:, 11]\n",
    "N = X.shape[0]\n",
    "d = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cf259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, test sets\n",
    "# random_state set to 42 for reproducibility, will change later\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=RAND_STATE)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=RAND_STATE)\n",
    "np.set_printoptions(threshold=1000000)  # Increases print threshold before cutting off matrix\n",
    "print(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Unscaled Data\n",
    "feature_names_orig = ['Age', 'Gender', 'Years_Since_Diagnosis', 'UPDRS_Score', 'Tremor_Severity', 'Motor_Function', 'Speech_Difficulty', 'Balance_Problems', 'Medications', 'Exercise_Level']\n",
    "feature_names_orig_numeric = ['Age', 'Years_Since_Diagnosis', 'UPDRS_Score', 'Tremor_Severity', 'Motor_Function', 'Speech_Difficulty', 'Balance_Problems']\n",
    "\n",
    "# Distributions for each feature\n",
    "X_train_orig_numeric = np.delete(X_train, np.array([1, 8, 9]), 1).astype(float)\n",
    "fig, axs = plt.subplots(7, 1, figsize=(10,10))\n",
    "for i in range (0,7):\n",
    "    \"\"\"\n",
    "    # Density plots\n",
    "    density = gaussian_kde(X_train_orig_numeric[: , i])\n",
    "    density.covariance_factor = lambda : .25\n",
    "    density._compute_covariance()\n",
    "    xs = np.linspace(X_train_orig_numeric[: , i].min(axis=0), X_train_orig_numeric[: , i].max(axis=0), 200)\n",
    "    axs[i].plot(xs, density(xs))\n",
    "    \"\"\"\n",
    "    # Histograms\n",
    "    axs[i].hist(X_train_orig_numeric[: , i])\n",
    "\n",
    "    axs[i].set_xlabel(feature_names_orig_numeric[i])\n",
    "fig.tight_layout()\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=16, fontweight='bold')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Plotting individual features against target variable\n",
    "fig, axs = plt.subplots(7, 1, figsize=(10,10))\n",
    "y_train_int = y_train.astype(int)\n",
    "for i in range (0,7):\n",
    "    axs[i].scatter(X_train_orig_numeric[:,i], y_train_int, s=1)\n",
    "    axs[i].set_xlabel(feature_names_orig_numeric[i])\n",
    "fig.tight_layout()\n",
    "plt.suptitle(\"Features vs. Target Variable\", fontsize=16, fontweight='bold')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Standard correlation coefficients for numeric variables against label\n",
    "print(f\"Correlation coefficients against label: \\n{feature_df[feature_names_orig_numeric].corrwith(target_df, axis=0).sort_values(ascending=False)}\")\n",
    "\n",
    "# Plot numeric variables against each other for correlation visualization\n",
    "#scatter_matrix(feature_df[feature_names_orig_numeric], figsize=(12,8))\n",
    "\n",
    "# Correlation matrix for numeric variables\n",
    "corr_df = feature_df[feature_names_orig_numeric].astype(float)\n",
    "corr_matrix = corr_df.corr()\n",
    "f = plt.figure()\n",
    "plt.matshow(corr_matrix, fignum=f.number)\n",
    "plt.xticks(range(corr_df.select_dtypes(['number']).shape[1]), corr_df.select_dtypes(['number']).columns, fontsize=8, rotation=-45)\n",
    "plt.yticks(range(corr_df.select_dtypes(['number']).shape[1]), corr_df.select_dtypes(['number']).columns, fontsize=8)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show(block=False)\n",
    "print(f\"Correlation Matrix: \\n{corr_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical features\n",
    "# Check handle_unknown parameter later for handling Medication feature\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "ord = OrdinalEncoder(categories=[[\"Low\", \"Moderate\", \"High\"]])\n",
    "ohe_cols = [1, 8]\n",
    "ord_cols = [9]\n",
    "\n",
    "# Not scaling one hot encoded or ordinal encoded columns\n",
    "scaler = StandardScaler()\n",
    "# scale_cols = [0, 2, 3, 4, 5, 6, 7]\n",
    "scale_cols = [0, 2, 3]  # not scaling variables with values from 1 - 5 here\n",
    "encoder = ColumnTransformer([(\"ohe\", ohe, ohe_cols), (\"ord\", ord, ord_cols), (\"scl\", scaler, scale_cols)], remainder='passthrough')\n",
    "X_train = encoder.fit_transform(X_train).astype(float)\n",
    "X_val = encoder.transform(X_val).astype(float)\n",
    "X_test = encoder.transform(X_test).astype(float)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "\n",
    "feature_names = ['Gender', 'Medications', 'Exercise_Level', 'Age', 'Years_Since_Diagnosis','UPDRS_Score', 'Tremor_Severity', 'Motor_Function', 'Speech_Difficulty', 'Balance_Problems']\n",
    "feature_names_transformed = ['Gender', 'Medications 1', 'Medications 2', 'Medications 3', 'Exercise_Level', 'Age', 'Years_Since_Diagnosis','UPDRS_Score', 'Tremor_Severity', 'Motor_Function', 'Speech_Difficulty', 'Balance_Problems']\n",
    "feature_names_numeric = ['Age', 'Years_Since_Diagnosis','UPDRS_Score', 'Tremor_Severity', 'Motor_Function', 'Speech_Difficulty', 'Balance_Problems']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Implementation standardizing all columns\n",
    "encoder = ColumnTransformer([(\"ohe\", ohe, ohe_cols), (\"ord\", ord, ord_cols)], remainder='passthrough')\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_val = encoder.transform(X_val)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Trying to scale labels to [-1, 0, 1]\n",
    "print(y_train)\n",
    "y_train = (y_train.astype('int') - 2).astype(str)\n",
    "y_val = (y_val.astype('int') - 2).astype(str)\n",
    "y_test = (y_test.astype('int') - 2).astype(str)\n",
    "print(y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5608857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Visualizing Encoded Scaled Data\n",
    "\n",
    "# Density charts of each feature for their distribution\n",
    "fig, axs = plt.subplots(3, 4, figsize=(10,10))\n",
    "for i in range (0,3):\n",
    "    for j in range (0,4):\n",
    "        density = gaussian_kde(X_train[: , i*4+j])\n",
    "        density.covariance_factor = lambda : .25\n",
    "        density._compute_covariance()\n",
    "        xs = np.linspace(-3, 6, 200)\n",
    "        axs[i, j].plot(xs, density(xs))\n",
    "        axs[i, j].set_xlabel(feature_names_transformed[i*4+j])\n",
    "fig.tight_layout()\n",
    "plt.show(block=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a582792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Plotting individual features against target variable\n",
    "fig, axs = plt.subplots(3, 4, figsize=(10,10))\n",
    "for i in range (0,3):\n",
    "    for j in range (0,4):\n",
    "        axs[i, j].scatter(X_train[:,i*4+j], y_train_int, s=1)\n",
    "        axs[i, j].set_xlabel(feature_names_transformed[i*4+j])\n",
    "fig.tight_layout()\n",
    "        \n",
    "# Correlation matrix for numeric variables\n",
    "scatter_matrix(feature_df[feature_names], figsize=(12,8))\n",
    "plt.show(block=False)\n",
    "\n",
    "# Standard correlation coefficients for numeric variables\n",
    "feature_df[feature_names_numeric].corrwith(target_df, axis=0).sort_values(ascending=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f46ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA / clustering unsupervised analysis\n",
    "# PCA to three components for visualizing clusters / feature transformation\n",
    "pca_model = PCA(n_components=3, random_state=RAND_STATE)\n",
    "pca_train = pca_model.fit_transform(X_train)\n",
    "pca_val = pca_model.transform(X_val)\n",
    "pca_test = pca_model.transform(X_test)\n",
    "#pca_data = pd.DataFrame(pca_train, columns=['PC1', 'PC2'])  # 2D dataframe for 2D PCA clusters\n",
    "pca_data = pd.DataFrame(pca_train, columns=['PC1', 'PC2', 'PC3'])  # 3D dataframe for 3D PCA clusters\n",
    "\n",
    "# Elbow method for finding optimal k: number of clusters\n",
    "wcss = []  # Using within cluster sum of squares for deciding k\n",
    "for i in range(1, 21):\n",
    "    kmeans_model = KMeans(n_clusters=i, random_state=RAND_STATE, n_init='auto').fit(X_train)\n",
    "    wcss.append(kmeans_model.inertia_)\n",
    "fig = plt.figure()\n",
    "plt.plot(range(1, 21), wcss, marker='o')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('K-means Elbow Graph')\n",
    "plt.show()\n",
    "\n",
    "# Optimal k = 4, running k-means clustering using optimal k\n",
    "kmeans_model = KMeans(n_clusters=4, random_state=RAND_STATE, n_init='auto').fit(X_train)\n",
    "pca_data['cluster'] = pd.Categorical(kmeans_model.labels_)\n",
    "\n",
    "# Plotting clusters on PCA axes\n",
    "fig = plt.figure()\n",
    "\n",
    "# 3D plot for 3-dimensional PCA\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(azim=-30, elev=30)  # Set azimuth and elevation angles, default is (-60,30)\n",
    "scatter = ax.scatter(pca_data['PC1'], pca_data['PC2'], pca_data['PC3'], c=pca_data['cluster'], cmap='Set3', alpha=0.7)\n",
    "\n",
    "\"\"\"\n",
    "# 2D plot for 2-dimensional PCA\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(pca_data['PC1'], pca_data['PC2'], c=pca_data['cluster'], cmap='Set3', alpha=0.7)\n",
    "\"\"\"\n",
    "legend1 = ax.legend(*scatter.legend_elements(), loc=\"upper left\", title=\"\")\n",
    "ax.add_artist(legend1)\n",
    "plt.title('Cluster Plot')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Redoing PCA with Minka's MLE to guess dimension\n",
    "pca_model = PCA(n_components='mle', random_state=RAND_STATE)\n",
    "pca_train = pca_model.fit_transform(X_train)\n",
    "pca_val = pca_model.transform(X_val)\n",
    "pca_test = pca_model.transform(X_test)\n",
    "print(f\"Number of PCA dimensions: {pca_model.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" First Model ------- Logistic Regression \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regression(X_train, X_test, y_train, y_test, lamb): # DEFINING logistic regression \n",
    "\n",
    "    # Tried newton-cg solver with l2 penalty, saga solver with l2 and l1 penalty (slow)\n",
    "    logreg = LogisticRegression(penalty='l2', solver='lbfgs', C=1/lamb, max_iter=10000, random_state=RAND_STATE)  # create a logistic regression model object\n",
    "                                                                                    # C: inverse of lambda\n",
    "                                                                                    # our problem is multiclass since we have three possible labels\n",
    "\n",
    "    \"\"\"Working on training set\"\"\"\n",
    "    logreg.fit(X_train, y_train) # optimizing our logistic regression model using our Training set\n",
    "                                 # This is where we find the best w\n",
    "    #train_acc = logreg.score(X_train, y_train) # accuracy on training set\n",
    "    y_train_hat = logreg.predict(X_train)\n",
    "    prec_train, rec_train, fscore_train, sup_train = precision_recall_fscore_support(y_train, y_train_hat, average='macro')\n",
    "\n",
    "    \"\"\"Working on test set\"\"\"\n",
    "    y_test_hat = logreg.predict(X_test) # predicting on test set\n",
    "    #test_acc = logreg.score(X_test, y_test) # computing accuracy on test set\n",
    "    \n",
    "    \"\"\"\n",
    "    w = logreg.coef_\n",
    "    intercept = logreg.intercept_\n",
    "    print('w: ', w)\n",
    "    print('intercept: ', intercept)\n",
    "    print(f\"y_train_hat:  {y_train_hat}\")\n",
    "    print(f\"true y train: {y_train}\")\n",
    "    print(f\"y_test_hat: {y_test_hat}\")\n",
    "    print(f\"true y val: {y_test}\")\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" Computing metrics\"\"\"\n",
    "    prec, rec, fscore, sup = precision_recall_fscore_support(y_test, y_test_hat, average='macro') # Using macro-averaging for metrics currently\n",
    "    metrics = (fscore, prec, rec, fscore_train)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe78278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALLING logistic regression that we defined above\n",
    "\n",
    "poly_transform_degrees = [1,2,3,4]\n",
    "lambda_values = [1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7]\n",
    "#lambda_values = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1]\n",
    "#lambda_values = np.logspace(-8,8,20) # a vector of our six lambda values that we use for regularization\n",
    "all_lambdas_best = []\n",
    "validation_fscores = []\n",
    "\n",
    "for d in poly_transform_degrees:\n",
    "    avg_fscores = []\n",
    "    train_accs = []\n",
    "    \"\"\"Transforming our features\"\"\"\n",
    "    print(\"THIS IS A DEGREE %d POLYNOMIAL TRANSFORM\" % d)\n",
    "    poly = PolynomialFeatures(d)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_val_poly = poly.transform(X_val)\n",
    "    #X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    for l in lambda_values:\n",
    "        print(\"LAMBDA = %f :\" % l)\n",
    "        metrics = log_regression(X_train_poly, X_val_poly, y_train, y_val, l)\n",
    "        print(\"fscore: %f\" % metrics[0])\n",
    "        print(\"precision: %f\" % metrics[1])\n",
    "        print(\"recall: %f\" % metrics[2])\n",
    "        print(\"Training fscore: %f\" % metrics[3])\n",
    "        avg_fscores.append(metrics[0])  # need to take average first if not using macro/macro averaging\n",
    "        train_accs.append(metrics[3])\n",
    "        print(\"-----------------------------------------------------\")\n",
    "\n",
    "    print(f\"Lambda values: {lambda_values}\")\n",
    "    print(f\"Training fscores: {train_accs}\")\n",
    "    print(f\"F scores: {avg_fscores}\")\n",
    "    # Plotting Regularization Lambda vs Accuracy\n",
    "    plt.ylim(0,1) \n",
    "    plt.xscale(\"log\",base=10)\n",
    "    plt.plot(lambda_values, train_accs, '.-')  # plot lambda vs train fscore\n",
    "    plt.plot(lambda_values,avg_fscores,'.-') # plot lambda vs val fscore\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.title(f'Logistic Regression Degree {d}, Lambda vs F Score')\n",
    "    plt.ylabel('F Score')\n",
    "    plt.xlabel('Lambda values')\n",
    "    plt.grid(True)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Comparing fscores for best hyperparameters\n",
    "\n",
    "    # Using lambda with highest val fscore, gets first lambda with maximum value since lower lambda usually has lower training error\n",
    "    best_lambda_ind = max(range(len(avg_fscores)), key=avg_fscores.__getitem__)\n",
    "    \"\"\"\n",
    "    # Gets first lambda with min difference between train and val fscores\n",
    "    avg_fscores_np = np.asarray(avg_fscores)\n",
    "    train_accs_np = np.asarray(train_accs)\n",
    "    best_lambda_ind = np.argmin(np.absolute(avg_fscores_np - train_accs_np))\n",
    "    \"\"\"\n",
    "    lambda_best = lambda_values[best_lambda_ind]\n",
    "    fscore_best = avg_fscores[best_lambda_ind]\n",
    "    print(f\"Comparing Logistic Regression with Degree {d} Transform: lambda = {lambda_best}, F score = {fscore_best}\")\n",
    "    all_lambdas_best.append(lambda_best)\n",
    "    validation_fscores.append(fscore_best)\n",
    "    print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b58326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train, X_test, y_train, y_test, lamb, t): # DEFINING SVM \n",
    "\n",
    "    \"\"\" Transformation will tell us which model to use\"\"\"\n",
    "    if (t == \"RBF\"): # our transformation is RBF KERNEL\n",
    "        SVM_model = SVC(C=1/lamb, kernel='rbf', random_state=RAND_STATE)\n",
    "    elif (t == \"Poly2\"): # our transformation is POLYNOMIAL KERNEL of DEGREE 2\n",
    "        SVM_model = SVC(C=1/lamb, kernel='poly', degree=2, random_state=RAND_STATE)  \n",
    "    elif (t == \"Poly3\"): # our transformation is POLYNOMIAL KERNEL of DEGREE 3\n",
    "        SVM_model = SVC(C=1/lamb, kernel='poly', degree=3, random_state=RAND_STATE)  \n",
    "    else: # t == \"Poly1\", includes PCA\n",
    "        SVM_model = SVC(C=1/lamb, kernel='poly', degree=1, random_state=RAND_STATE)  \n",
    "\n",
    "    \"\"\" Working on training set\"\"\"\n",
    "    SVM_model.fit(X_train, y_train) # optimizing our SVM model using training set\n",
    "                                    # finding the best w\n",
    "    #train_acc = SVM_model.score(X_train, y_train) # accuracy on training set\n",
    "    y_train_hat = SVM_model.predict(X_train)\n",
    "    prec_train, rec_train, fscore_train, sup_train = precision_recall_fscore_support(y_train, y_train_hat, average='macro')\n",
    "    \n",
    "    \"\"\" Working on test set\"\"\"\n",
    "    y_test_hat = SVM_model.predict(X_test) # predicting on test set\n",
    "    #test_acc = SVM_model.score(X_test, y_test) # computing accuracy on test set\n",
    "    \n",
    "    \"\"\"\n",
    "    w = logreg.coef_\n",
    "    intercept = logreg.intercept_\n",
    "    print('w: ', w)\n",
    "    print('intercept: ', intercept)\n",
    "    print(f\"y_train_hat:  {y_train_hat}\")\n",
    "    print(f\"true y train: {y_train}\")\n",
    "    print(f\"y_test_hat: {y_test_hat}\")\n",
    "    print(f\"true y val: {y_test}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"Computing metrics\"\"\"\n",
    "    prec, rec, fscore, sup = precision_recall_fscore_support(y_test, y_test_hat, average='macro') # Using macro-averaging for metrics currently\n",
    "    metrics = (fscore, prec, rec, fscore_train)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALLING SVM that we defined above\n",
    "\n",
    "svm_transformations = [\"Poly1\",\"Poly2\",\"Poly3\",\"RBF\",\"PCA\"]\n",
    "lambda_values = [1e-3,1e-2,1e-1,1,1e1,1e2]\n",
    "\n",
    "for t in svm_transformations:\n",
    "    avg_fscores = []\n",
    "    train_accs = []\n",
    "    if (t == \"PCA\"):\n",
    "        print(\"THE TRANSFORMATION IS PCA\")\n",
    "\n",
    "        for l in lambda_values:\n",
    "\n",
    "            print(\"LAMBDA = %f :\" % l)\n",
    "\n",
    "            metrics = SVM(pca_train, pca_val, y_train, y_val, l,t)\n",
    "\n",
    "            print(\"fscore: %f\" % metrics[0])\n",
    "            print(\"precision: %f\" % metrics[1])\n",
    "            print(\"recall: %f\" % metrics[2])\n",
    "            print(\"Training fscore: %f\" % metrics[3])\n",
    "            avg_fscores.append(metrics[0])\n",
    "            train_accs.append(metrics[3])\n",
    "            print(\"-----------------------------------------------------\")\n",
    "    else:\n",
    "        if(t == \"Poly1\"):\n",
    "            print(\"THE TRANSFORMATION IS POLYNOMIAL OF DEGREE 1\")\n",
    "        elif(t == \"Poly2\"):\n",
    "            print(\"THE TRANSFORMATION IS POLYNOMIAL OF DEGREE 2\")\n",
    "        elif(t == \"Poly3\"):\n",
    "            print(\"THE TRANSFORMATION IS POLYNOMIAL OF DEGREE 3\")\n",
    "        else: # t == \"RBF\"\n",
    "            print(\"THE TRANSFORMATION IS RBF KERNEL\")\n",
    "\n",
    "        # Polynomial-transformed features used if not PCA\n",
    "        for l in lambda_values:\n",
    "\n",
    "            print(\"LAMBDA = %f :\" % l)\n",
    "\n",
    "            metrics = SVM(X_train, X_val, y_train, y_val, l,t)\n",
    "\n",
    "            print(\"fscore: %f\" % metrics[0])\n",
    "            print(\"precision: %f\" % metrics[1])\n",
    "            print(\"recall: %f\" % metrics[2])\n",
    "            print(\"Training fscore: %f\" % metrics[3])\n",
    "            avg_fscores.append(metrics[0])\n",
    "            train_accs.append(metrics[3])\n",
    "            print(\"-----------------------------------------------------\")\n",
    "\n",
    "    print(f\"Lambda values: {lambda_values}\")\n",
    "    print(f\"Training fscores: {train_accs}\")\n",
    "    print(f\"F scores: {avg_fscores}\")\n",
    "    # Plotting Regularization Lambda vs Accuracy\n",
    "    plt.ylim(0,1) \n",
    "    plt.xscale(\"log\",base=10)\n",
    "    plt.plot(lambda_values, train_accs, '.-')  # plot lambda vs train fscore\n",
    "    plt.plot(lambda_values,avg_fscores,'.-') # plot lambda vs val fscore\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.title(f'SVM {t}, Lambda vs F Score')\n",
    "    plt.ylabel('F Score')\n",
    "    plt.xlabel('Lambda values')\n",
    "    plt.grid(True)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Comparing fscores for best hyperparameters\n",
    "\n",
    "    # Using lambda with highest val fscore, gets first lambda with maximum value since lower lambda usually has lower training error\n",
    "    best_lambda_ind = max(range(len(avg_fscores)), key=avg_fscores.__getitem__)\n",
    "    \"\"\"\n",
    "    # Gets first lambda with min difference between train and val fscores\n",
    "    avg_fscores_np = np.asarray(avg_fscores)\n",
    "    train_accs_np = np.asarray(train_accs)\n",
    "    best_lambda_ind = np.argmin(np.absolute(avg_fscores_np - train_accs_np))\n",
    "    \"\"\"\n",
    "    lambda_best = lambda_values[best_lambda_ind]\n",
    "    fscore_best = avg_fscores[best_lambda_ind]\n",
    "    print(f\"Comparing SVM with {t} Transform: lambda = {lambda_best}, F score = {fscore_best}\")\n",
    "    all_lambdas_best.append(lambda_best)\n",
    "    validation_fscores.append(fscore_best)\n",
    "    print(\"=====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(X_train, X_test, y_train, y_test, lamb, nn_structure): # DEFINING Neural Network \n",
    "\n",
    "    # Tried logistic, tanh activations\n",
    "    # Tried lbfgs solver\n",
    "    # Tried higher initial learning rate\n",
    "    # Tried PCA as input\n",
    "    NN_model = MLPClassifier(hidden_layer_sizes = nn_structure, activation= 'relu', solver='adam', alpha=lamb, max_iter=10000, learning_rate='constant', learning_rate_init=0.001, random_state=RAND_STATE)  \n",
    "\n",
    "\n",
    "    \"Working on test set\"\n",
    "    NN_model.fit(X_train, y_train)\n",
    "    #train_acc = NN_model.score(X_train, y_train)\n",
    "    y_train_hat = NN_model.predict(X_train)\n",
    "    prec_train, rec_train, fscore_train, sup_train = precision_recall_fscore_support(y_train, y_train_hat, average='macro')\n",
    "\n",
    "\n",
    "    \"Working on training set\"\n",
    "    y_test_hat = NN_model.predict(X_test)\n",
    "    #test_acc = NN_model.score(X_test, y_test)\n",
    "    \n",
    "    \"\"\"\n",
    "    w = logreg.coef_\n",
    "    intercept = logreg.intercept_\n",
    "    print('w: ', w)\n",
    "    print('intercept: ', intercept)\n",
    "    print(f\"y_train_hat:  {y_train_hat}\")\n",
    "    print(f\"true y train: {y_train}\")\n",
    "    print(f\"y_test_hat: {y_test_hat}\")\n",
    "    print(f\"true y val: {y_test}\")\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"Computing metrics\"\"\"\n",
    "    prec, rec, fscore, sup = precision_recall_fscore_support(y_test, y_test_hat, average='macro')\n",
    "    metrics = (fscore, prec, rec, fscore_train)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de69b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALLING our Neural Network function defined above\n",
    "\n",
    "nn_structure = [(10,), (10,10), (10,10,10), (50,)] # NOTE: these are HIDDEN layer sizes (excluding the input and output layers)\n",
    "                                           # e.g. our first architecture has one hidden layer with 10 nodes\n",
    "                                                 # our second architecture has two hidden layers with 10 nodes each\n",
    "                                         \n",
    "lambda_values = [1e-3,1e-2,1e-1,1,1e1,1e2]\n",
    "\n",
    "for n in nn_structure:\n",
    "    avg_fscores = []\n",
    "    train_accs = []\n",
    "    print(\"THIS INNER LAYER ARCHITECTURE IS \", n)\n",
    "\n",
    "    for l in lambda_values:\n",
    "\n",
    "        print(\"LAMBDA = %f :\" % l)\n",
    "\n",
    "        metrics = NN(X_train, X_val, y_train, y_val, l, n)\n",
    "        print(\"fscore: %f\" % metrics[0])\n",
    "        print(\"precision: %f\" % metrics[1])\n",
    "        print(\"recall: %f\" % metrics[2])\n",
    "        print(\"training fscore: %f\" % metrics[3])\n",
    "        avg_fscores.append(metrics[0])\n",
    "        train_accs.append(metrics[3])\n",
    "        print(\"-----------------------------------------------------\")\n",
    "\n",
    "    print(f\"Lambda values: {lambda_values}\")\n",
    "    print(f\"Training fscores: {train_accs}\")\n",
    "    print(f\"F scores: {avg_fscores}\")\n",
    "    # Plotting Regularization Lambda vs Accuracy\n",
    "    plt.ylim(0,1) \n",
    "    plt.xscale(\"log\",base=10)\n",
    "    plt.plot(lambda_values, train_accs, '.-')  # plot lambda vs train fscore\n",
    "    plt.plot(lambda_values,avg_fscores,'.-') # plot lambda vs val fscore\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.title(f'Neural Network of Structure {n}, Lambda vs F Score')\n",
    "    plt.ylabel('F Score')\n",
    "    plt.xlabel('Lambda values')\n",
    "    plt.grid(True)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Comparing fscores for best hyperparameters\n",
    "\n",
    "    # Using lambda with highest val fscore, gets first lambda with maximum value since lower lambda usually has lower training error\n",
    "    best_lambda_ind = max(range(len(avg_fscores)), key=avg_fscores.__getitem__)\n",
    "    \"\"\"\n",
    "    # Gets first lambda with min difference between train and val fscores\n",
    "    avg_fscores_np = np.asarray(avg_fscores)\n",
    "    train_accs_np = np.asarray(train_accs)\n",
    "    best_lambda_ind = np.argmin(np.absolute(avg_fscores_np - train_accs_np))\n",
    "    \"\"\"\n",
    "    lambda_best = lambda_values[best_lambda_ind]\n",
    "    fscore_best = avg_fscores[best_lambda_ind]\n",
    "    print(f\"Comparing Neural Network of Structure {n}: lambda = {lambda_best}, F score = {fscore_best}\")\n",
    "    all_lambdas_best.append(lambda_best)\n",
    "    validation_fscores.append(fscore_best)\n",
    "    print(\"=============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# NN with PCA transform\n",
    "for n in nn_structure:\n",
    "    avg_fscores = []\n",
    "    train_accs = []\n",
    "    print(\"Neural network models with PCA for features\")\n",
    "    print(\"THIS INNER LAYER ARCHITECTURE IS \", n)\n",
    "\n",
    "    for l in lambda_values:\n",
    "\n",
    "        print(\"LAMBDA = %f :\" % l)\n",
    "\n",
    "        metrics = NN(pca_train, pca_val, y_train, y_val, l, n)\n",
    "        print(\"fscore: %f\" % metrics[0])\n",
    "        print(\"precision: %f\" % metrics[1])\n",
    "        print(\"recall: %f\" % metrics[2])\n",
    "        print(\"training fscore: %f\" % metrics[3])\n",
    "        avg_fscores.append(metrics[0])\n",
    "        train_accs.append(metrics[3])\n",
    "        print(\"-----------------------------------------------------\")\n",
    "\n",
    "    print(f\"Lambda values: {lambda_values}\")\n",
    "    print(f\"Training fscores: {train_accs}\")\n",
    "    print(f\"F scores: {avg_fscores}\")\n",
    "    # Plotting Regularization Lambda vs Accuracy\n",
    "    plt.ylim(0,1) \n",
    "    plt.xscale(\"log\",base=10)\n",
    "    plt.plot(lambda_values, train_accs, '.-')  # plot lambda vs train fscore\n",
    "    plt.plot(lambda_values,avg_fscores,'.-') # plot lambda vs val fscore\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.title(f'Neural Network of Structure {n} with PCA, Lambda vs F Score')\n",
    "    plt.ylabel('F Score')\n",
    "    plt.xlabel('Lambda values')\n",
    "    plt.grid(True)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Comparing fscores for best hyperparameters\n",
    "\n",
    "    # Using lambda with highest val fscore, gets first lambda with maximum value since lower lambda usually has lower training error\n",
    "    best_lambda_ind = max(range(len(avg_fscores)), key=avg_fscores.__getitem__)\n",
    "    \n",
    "    # Gets first lambda with min difference between train and val fscores\n",
    "    #avg_fscores_np = np.asarray(avg_fscores)\n",
    "    #train_accs_np = np.asarray(train_accs)\n",
    "    #best_lambda_ind = np.argmin(np.absolute(avg_fscores_np - train_accs_np))\n",
    "    \n",
    "    lambda_best = lambda_values[best_lambda_ind]\n",
    "    fscore_best = avg_fscores[best_lambda_ind]\n",
    "    print(f\"Comparing Neural Network of Structure {n} with PCA: lambda = {lambda_best}, F score = {fscore_best}\")\n",
    "    all_lambdas_best.append(lambda_best)\n",
    "    validation_fscores.append(fscore_best)\n",
    "    print(\"=============================================================\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896737bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First four are logreg poly1-4\n",
    "# Next five are SVM poly1-3, RBF, PCA\n",
    "# Next four are NN with structures (10,), (10,10), (10,10,10), (50,)\n",
    "# Next four are NN with PCA and structures (10,), (10,10), (10,10,10), (50,)\n",
    "print(f\"Validation Set Lambdas: {all_lambdas_best}\")\n",
    "print(f\"Validation Set F Scores: {validation_fscores}\")\n",
    "\n",
    "validation_fscores_logreg = validation_fscores[0:4]\n",
    "lambdas_logreg = all_lambdas_best[0:4]\n",
    "transforms_logreg = ['Poly1', 'Poly2', 'Poly3', 'Poly4']\n",
    "validation_fscores_SVM = validation_fscores[4:9]\n",
    "lambdas_SVM = all_lambdas_best[4:9]\n",
    "transforms_SVM = ['Poly1', 'Poly2', 'Poly3', 'RBF', 'PCA']\n",
    "validation_fscores_NN = validation_fscores[9:17]\n",
    "#lambdas_NN = all_lambdas_best[9:17]\n",
    "#transforms_NN = ['(10,)', '(10,10)', '(10,10,10)', '(50,)', 'PCA (10,)', 'PCA (10,10)', 'PCA (10,10,10)', 'PCA (50,)']\n",
    "lambdas_NN = all_lambdas_best[9:13]\n",
    "transforms_NN = ['(10,)', '(10,10)', '(10,10,10)', '(50,)']\n",
    "\n",
    "# Logreg bar chart for feature transformations\n",
    "plt.bar(transforms_logreg, validation_fscores_logreg)\n",
    "plt.title(f'Validation F Scores for Feature Transforms on Logistic Regression')\n",
    "plt.ylabel('F Score')\n",
    "plt.xlabel('Transform')\n",
    "plt.show(block=False)\n",
    "\n",
    "# SVM bar chart for feature transformations\n",
    "plt.bar(transforms_SVM, validation_fscores_SVM)\n",
    "plt.title(f'Validation F Scores for Feature Transforms on SVM')\n",
    "plt.ylabel('F Score')\n",
    "plt.xlabel('Transform')\n",
    "plt.show(block=False)\n",
    "\n",
    "# NN bar chart for feature transformations\n",
    "plt.bar(transforms_NN, validation_fscores_NN)\n",
    "plt.title(f'Validation F Scores for Feature Transforms on Neural Network')\n",
    "plt.ylabel('F Score')\n",
    "plt.xlabel('Architecture')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf46b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for best feature transform / regularization for each model\n",
    "test_fscores = []\n",
    "\n",
    "# Chooses feature transform with highest validation fscore based on best lambda\n",
    "best_logreg_ind = max(range(len(validation_fscores_logreg)), key=validation_fscores_logreg.__getitem__)\n",
    "poly = PolynomialFeatures(poly_transform_degrees[best_logreg_ind])\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "test_fscores.append(log_regression(X_train_poly, X_test_poly, y_train, y_test, lambdas_logreg[best_logreg_ind])[0])\n",
    "\n",
    "best_SVM_ind = max(range(len(validation_fscores_SVM)), key=validation_fscores_SVM.__getitem__)\n",
    "if (svm_transformations[best_SVM_ind] == 'PCA'):\n",
    "    test_fscores.append(SVM(pca_train, pca_test, y_train, y_test, lambdas_SVM[best_SVM_ind], svm_transformations[best_SVM_ind])[0])\n",
    "else:\n",
    "    test_fscores.append(SVM(X_train, X_test, y_train, y_test, lambdas_SVM[best_SVM_ind], svm_transformations[best_SVM_ind])[0])\n",
    "\n",
    "best_NN_ind = max(range(len(validation_fscores_NN)), key=validation_fscores_NN.__getitem__)\n",
    "\"\"\"\n",
    "if (best_NN_ind < 4):  # No PCA\n",
    "    test_fscores.append(NN(X_train, X_test, y_train, y_test, lambdas_NN[best_NN_ind], nn_structure[best_NN_ind % 4])[0])\n",
    "else:  # PCA\n",
    "    test_fscores.append(NN(pca_train, pca_test, y_train, y_test, lambdas_NN[best_NN_ind], nn_structure[best_NN_ind % 4])[0])\n",
    "\"\"\"\n",
    "test_fscores.append(NN(pca_train, pca_test, y_train, y_test, lambdas_NN[best_NN_ind], nn_structure[best_NN_ind])[0])\n",
    "\n",
    "print(f'Best Logreg: Poly{poly_transform_degrees[best_logreg_ind]}, Lambda = {lambdas_logreg[best_logreg_ind]}')\n",
    "print(f'Best SVM: {svm_transformations[best_SVM_ind]}, Lambda = {lambdas_SVM[best_SVM_ind]}')\n",
    "\"\"\"\n",
    "if (best_NN_ind < 4):\n",
    "    print(f'Best NN: {nn_structure[best_NN_ind]}, Lambda = {lambdas_NN[best_NN_ind]}')\n",
    "else:\n",
    "    print(f'Best NN: PCA {nn_structure[best_NN_ind]}, Lambda = {lambdas_NN[best_NN_ind]}')\n",
    "\"\"\"\n",
    "print(f'Best NN: {nn_structure[best_NN_ind]}, Lambda = {lambdas_NN[best_NN_ind]}')\n",
    "print(f'Test Set F Scores for Logistic Regression, SVM, Neural Network: {test_fscores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80d72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
